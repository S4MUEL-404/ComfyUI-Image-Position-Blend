print("Loading ComfyUI-Image-Position-Blend node...")

class ImagePositionBlend:
    """
    A node that blends two images by positioning Image A over Image B at specified X,Y coordinates,
    with options for mirroring, rotation, and alpha blending for transparency.
    """
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_a": ("IMAGE",),  # å‰æ™¯å›¾ç‰‡
                "image_b": ("IMAGE",),  # èƒŒæ™¯å›¾ç‰‡
                "x_position": ("INT", {
                    "default": 0,
                    "min": -4096,
                    "max": 4096,
                    "step": 1,
                    "display": "number"
                }),
                "y_position": ("INT", {
                    "default": 0,
                    "min": -4096,
                    "max": 4096,
                    "step": 1,
                    "display": "number"
                }),
                "mirror": (["None", "Horizontal", "Vertical"], {
                    "default": "None"
                }),
                "rotation": ("FLOAT", {
                    "default": 0.0,
                    "min": -360.0,
                    "max": 360.0,
                    "step": 1.0,
                    "display": "number"
                }),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("blended_image",)
    FUNCTION = "blend_images"
    CATEGORY = "ğŸ’€Image Position Blend"  # ç›´æ¥æ˜¾ç¤ºåœ¨ "Add Node" æ ¹èœå•
    OUTPUT_NODE = False

    def blend_images(self, image_a, image_b, x_position, y_position, mirror, rotation):
        import torch
        import numpy as np
        from PIL import Image

        # å°†å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œä¿ç•™æ‰€æœ‰é€šé“ï¼ˆåŒ…æ‹¬ Alpha é€šé“ï¼‰
        img_a = image_a.cpu().numpy()[0] if image_a.shape[0] == 1 else image_a.cpu().numpy()
        img_b = image_b.cpu().numpy()[0] if image_b.shape[0] == 1 else image_b.cpu().numpy()

        # æ£€æŸ¥æ˜¯å¦æœ‰ Alpha é€šé“ï¼ˆRGBA æ ¼å¼ï¼‰
        if img_a.shape[2] == 4:  # å¦‚æœå›¾ç‰‡Aæœ‰ Alpha é€šé“
            # åˆ†ç¦» RGB å’Œ Alpha é€šé“
            img_a_rgb = img_a[..., :3]  # RGB é€šé“
            img_a_alpha = img_a[..., 3]  # Alpha é€šé“
        else:
            # å¦‚æœæ²¡æœ‰ Alpha é€šé“ï¼Œå‡è®¾å®Œå…¨ä¸é€æ˜
            img_a_rgb = img_a
            img_a_alpha = np.ones((img_a.shape[0], img_a.shape[1]), dtype=np.float32)

        # å°†å‰æ™¯å›¾ç‰‡è½¬æ¢ä¸º PIL æ ¼å¼ä»¥ä¾¿å¤„ç†é•œåƒå’Œæ—‹è½¬
        # ç”±äº PIL å¤„ç†é€æ˜åº¦æ—¶éœ€è¦ RGBA æ ¼å¼ï¼Œæˆ‘ä»¬å…ˆå°† RGB å’Œ Alpha åˆ†å¼€å¤„ç†
        img_a_pil = Image.fromarray((img_a_rgb * 255).astype(np.uint8))
        img_a_alpha_pil = Image.fromarray((img_a_alpha * 255).astype(np.uint8))

        # å¤„ç†é•œåƒ
        if mirror == "Horizontal":
            img_a_pil = img_a_pil.transpose(Image.FLIP_LEFT_RIGHT)
            img_a_alpha_pil = img_a_alpha_pil.transpose(Image.FLIP_LEFT_RIGHT)
        elif mirror == "Vertical":
            img_a_pil = img_a_pil.transpose(Image.FLIP_TOP_BOTTOM)
            img_a_alpha_pil = img_a_alpha_pil.transpose(Image.FLIP_TOP_BOTTOM)

        # å¤„ç†æ—‹è½¬
        if rotation != 0:
            img_a_pil = img_a_pil.rotate(rotation, expand=True)
            img_a_alpha_pil = img_a_alpha_pil.rotate(rotation, expand=True)

        # å°†å¤„ç†åçš„å›¾ç‰‡è½¬æ¢å› numpy æ•°ç»„
        img_a_rgb = np.array(img_a_pil).astype(np.float32) / 255.0
        img_a_alpha = np.array(img_a_alpha_pil).astype(np.float32) / 255.0

        # è·å–å›¾ç‰‡å°ºå¯¸ (height, width, channels)
        height_a, width_a = img_a_rgb.shape[:2]
        height_b, width_b = img_b.shape[:2]

        # åˆ›å»ºè¾“å‡ºç”»å¸ƒï¼Œä½¿ç”¨image_bçš„å°ºå¯¸
        output = np.copy(img_b)

        # è®¡ç®—å®é™…çš„æ”¾ç½®ä½ç½®ï¼Œç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
        x_start = max(0, x_position)
        y_start = max(0, y_position)
        
        # è®¡ç®—image_aåœ¨image_bä¸­çš„æœ‰æ•ˆåŒºåŸŸ
        x_end = min(width_b, x_start + width_a)
        y_end = min(height_b, y_start + height_a)
        
        # è®¡ç®—image_açš„è£å‰ªåŒºåŸŸ
        a_x_start = max(0, -x_position)
        a_y_start = max(0, -y_position)
        a_x_end = a_x_start + (x_end - x_start)
        a_y_end = a_y_start + (y_end - y_start)

        # å¦‚æœæœ‰é‡å åŒºåŸŸï¼Œè¿›è¡Œ Alpha æ··åˆ
        if x_end > x_start and y_end > y_start:
            # æå–å‰æ™¯å’ŒèƒŒæ™¯çš„åŒºåŸŸ
            fg_rgb = img_a_rgb[a_y_start:a_y_end, a_x_start:a_x_end]
            fg_alpha = img_a_alpha[a_y_start:a_y_end, a_x_start:a_x_end, np.newaxis]  # æ‰©å±• Alpha ç»´åº¦ä»¥åŒ¹é… RGB
            bg_rgb = output[y_start:y_end, x_start:x_end]

            # Alpha æ··åˆå…¬å¼ï¼šoutput = fg * alpha + bg * (1 - alpha)
            blended_rgb = fg_rgb * fg_alpha + bg_rgb * (1 - fg_alpha)

            # å°†æ··åˆåçš„åŒºåŸŸå†™å›è¾“å‡ºç”»å¸ƒ
            output[y_start:y_end, x_start:x_end] = blended_rgb

        # è½¬æ¢ä¸ºå¼ é‡å¹¶è¿”å›
        output_tensor = torch.from_numpy(output).unsqueeze(0)
        return (output_tensor,)

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImagePositionBlend": ImagePositionBlend
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°
NODE_DISPLAY_NAME_MAPPINGS = {
    "ImagePositionBlend": "ğŸ’€Image Position Blend"
}